## 메모리

<img width="692" alt="image" src="https://github.com/user-attachments/assets/44342267-837c-42b3-b75f-06e69ac2dcb7" />

먼저, 프로세스의 주소(Address)는 **논리적 주소(Logical address)**와 **물리적 주소(Physical address)**로 나뉜다.

논리적 주소는 **가상 주소(Virtual address)**라고도 하며, CPU가 생성하는 주소이다. 프로세스마다 독립적으로 가지는 주소 공간이기 때문에 프로세스의 내부에서 사용하고, 각 프로세스마다 0부터 시작한다. 

물리적 주소는 프로세스가 실행되기 위해 실제로 메모리(RAM)에 올라가는 위치이다. 
**Address Binding**은 **어떤 프로그램이 메모리의 어느 위치에, 즉 어떤 물리적 주소에 load 될지를 결정하는 과정**이다.

이는 binding 하는 시점에 따라 분류된다.

<img width="696" alt="image" src="https://github.com/user-attachments/assets/b7ad858f-d6df-46b8-b5c1-e349818fbd63" />


**1. Compile Time**

**프로세스의 물리적 주소가 컴파일 때 정해진다.** 프로세스가 메모리의 어느 위치에 들어갈지 미리 알고 있다면 컴파일러가 절대 주소(Absolute address), 즉 고정된 주소를 생성한다. 따라서 만약 위치가 변경된다면 재컴파일을 해주어야 한다.

**컴파일 타임 주소 할당은 프로세스 내부에서 사용하는 논리적 주소와 물리적 주소가 동일하다.**

컴파일 타임 주소 할당의 문제점은, 주소가 고정되어 있기 때문에 메모리 상에 빈 공간이 많이 발생할 수 있어 비효율적이고, 로드하려는 위치에 이미 다른 프로세스가 존재할 수 있다.

**2. Load Time**

프로세스가 메모리의 어느 위치에 들어갈지 미리 알 수 없다면 컴파일러는 Relocatable code를 생성해야 한다. Relocatable code는 메모리의 어느 위치에서나 수행될 수 있는 기계 언어 코드이다.

그리고 **Loader가 프로세스를 메모리에 load 하는 시점에 물리적 주소를 결정한다.**

따라서 로드 타임 주소 할당은 논리적 주소와 물리적 주소가 다르다.

하지만, 프로세스 내에 메모리를 참조하는 명령어들이 많아서 이들의 주소를 다 바꿔줘야 하기 때문에, 로딩할 때의 시간이 매우 커질 수 있다는 단점이 있다.

따라서 컴파일 타임과 로드 타임 주소 할당은 실제로 잘 쓰이지 않는다.

**3. Execution Time (Run time)**

**프로세스가 수행이 시작된 이후에 프로세스가 실행될 때 메모리 주소를 바꾸는 방법이다.** 즉, **Runtime때 물리적 주소가 결정되며 실행 도중에 주소가 바뀔 수 있다.** CPU가 주소를 참조할 때마다 address mapping table을 이용하여 binding을 점검한다.

런타임 주소 할당은 **MMU(Memory Management Unit)**라는 하드웨어 장치를 사용하여 논리적 주소를 물리적 주소로 바꿔준다. 프로세스가 CPU에서 수행되면서 생성해내는 모든 주소값에 대해서 base register의 값을 더해주어 물리적 주소를 생성하는 방식이다. base register는 하나이므로 프로세스끼리 공유한다.

아래의 그림은 MMU가 어떤 방식으로 프로세스의 논리적 주소를 물리적 주소로 변환되는지를 보여준다.

<img width="690" alt="image" src="https://github.com/user-attachments/assets/11d2cdc2-c94a-4323-8391-cd6e4c06e920" />

**Limit register**는 **논리적 주소의 범위이며, 잘못된 메모리를 참조하지 않도록 막아주는 기능을 한다.** 그리고 **Base register(Relocation register)**는 **접근할 수 있는 물리적 주소의 최솟값을 나타낸다.**

주의해야 할 점은, 만약 커널 모드인 경우에는 MMU가 물리적인 주소로 변환하지 않고 논리적 주소를 그대로 사용한다. 따라서 커널 모드인지 체크하는 과정도 포함되어 있다.

###  Swapping

메모리는 크기가 크지 않기 때문에 프로세스를 임시로 디스크에 보냈다가 다시 메모리에 로드해야 하는 상황이 생긴다. 이때 디스크로 내보내는 것을 **swap out**, 메모리로 들여보내는 것을 **swap in**이라고 한다. 일반적으로 중기 스케줄러에 의해 swap out 시킬 프로세스를 선정하며, 우선순위에 따라 어떤 프로세스를 swap in/out 할지 결정한다. 우선순위가 낮은 프로세스를 swap out 시키고, 높은 프로세스를 메모리에 올려놓는 방식이다.

만약 Compile time이나 Load time binding인 경우 원래 메모리 위치로 swap in 해야 하고, Execution time binding인 경우 추후 빈 메모리 영역 아무 곳에나 올릴 수 있다.

swap 하는데 걸리는 시간의 대부분은 디스크 전송 시간이다.

### Contiguous Allocation

메모리는 일반적으로 커널 영역과 사용자 프로세스 영역으로 나뉘어서 사용된다. 그중 사용자 프로세스 영역의 할당 방법으로는 **Contiguous Allocation(연속적 할당), Noncontiguous Allocation(비연속적 할당)**으로 나뉜다.

**Contiguous Allocation 시스템은 말 그대로, 각 프로세스들이 연속적인 메모리 공간을 차지하게 되는 것**이다.

각 프로세스를 메모리에 담기 위해 메모리는 미리 공간을 분할해두는데, 고정된 크기로 나누는 고정 분할 방식과 프로세스의 크기를 고려해서 나누는 가변 분할 방식이 있다.

**고정 분할(Fixed partition)**은 분할의 크기가 모두 동일하거나 혹은 서로 다를 수 있다. 분할 당 하나의 프로세스가 적재되기 때문에 동시에 메모리에 load 되는 프로세스의 수가 고정된다. 또 수행 가능한 프로세스의 최대 크기가 제한된다.

**가변 분할(Variable partition)**은 프로세스의 크기를 고려해서 할당하기 때문에 분할의 크기나 개수가 동적으로 변한다. 이를 위해서는 기술적인 관리 기법이 필요하다.

Contiguous Allocation에서 메모리를 분할하는 각 단위는 **Block**이고, 프로세스가 사용할 수 있는 Block을 **Hole**이라고 한다.

다양한 크기의 Hole들이 메모리 여러 곳에 흩어져 있고, 프로세스가 도착하면 수용 가능한 Hole을 할당시켜준다.

가변 분할 방식에서 크기가 n인 프로세스가 들어갈 가장 적절한 Hole을 찾는 문제를 **Dynamic Storage-Allocation Problem**이라고 하는데, 세 종류의 해결법이 있다.

### 단편화(Fragmentation)

프로세스들이 메모리에 적재되고 제거되는 일이 반복되면 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 공간들이 늘어나게 되는 현상을 말한다.

**외부 단편화(External Fragmentation)**와 **내부 단편화(Internal Fragmentation)**로 나뉜다.

**외부 단편화는 총공간을 계산했을 때 프로세스가 들어갈 수 있는 메모리가 있음에도 불구하고 공간들이 연속하지 않아 사용할 수 없는 경우**를 말한다.

**내부 단편화는 프로세스가 사용하는 메모리 공간보다 분할된 공간이 더 커서 메모리가 남는 경우를 말한다.** 예를 들어 1000 크기의 분할이 있고 990 크기의 프로세스가 들어갈 때, 10만큼의 공간이 남게 되는데 이 현상을 내부 단편화라고 한다.

<img width="668" alt="image" src="https://github.com/user-attachments/assets/49331809-1c61-40b8-ad87-09c322ee60c0" />


##### 1. 페이징 기법(Paging)

외부 단편화의 압축 작업의 비효율성을 해결하기 위한 방법으로, 메모리는 **프레임(Frame)**, 프로세스는 **페이지(Page)**라 불리는 고정 크기의 블록(Block)으로 분리된다. 블록의 크기는 2의 거듭제곱 꼴이다.

가상기억장치내의 프로세스를 일정하게 분할하여 주기억장치의 분산된 공간에 적재시킨 후 프로세스를 수행시키는 기법

<img width="681" alt="image" src="https://github.com/user-attachments/assets/bb8307d0-7a21-452d-a3ea-d22858b77f86" />


**<paging의 장점>**

- page들이 연속할 필요가 없어 외부 단편화를 해결할 수 있다.
- 할당과 해제가 빠르다.
- swap out이 간단하다.
- 코드를 쉽게 공유할 수 있다(Shared pages). 코드가 pure code라면 공유가 가능하며 read-only로 프로세스 간에 하나의 코드만 메모리에 올린다.

**<paging의 단점>**

- 내부 단편화를 해결하지 못한다.
- page table을 저장하기 위한 메모리가 추가로 소모된다.
  - page table이 메모리에 상주하기 때문에 메모리에 접근하는 연산은 2번의 메모리 접근이 필요하게 되어 속도가 느리다. (page table에 접근 + 실제 연산)

CPU에 의해 만들어진 Logical address는 **page number**와 **page offset** 두 부분으로 나뉜다.
page number는 page table의 인덱스로써 page table에 접근할 때 사용된다.
page offset은 물리적 주소를 얻을 때 사용되고, page table의 base address에 page offset을 더하면 물리적 주소를 구할 수 있다.

**page table은 프로세스마다 존재하며 메인 메모리에 상주한다.** page table이 대부분 매우 크기 때문에 이를 구현하기 위해 비용이 비싼 register를 사용하는 것은 적절하지 않기 때문이다. 
따라서 page table은 메인 메모리에 저장하고, **PTBR(Page-Table Base Register)**라는 레지스터가 page table을 가리키도록 한다. 만약 Context Switch가 발생하는 경우 이 레지스터의 내용만 변경하면 된다.

#### Translation Look-aside Buffer

**TLB(Translation Look-aside Buffer)**는 **메모리 주소 변환을 위한 별도의 캐시 메모리로, page table에서 빈번히 참조되는 일부 엔트리를 caching 하고 있다.** TLB는 **key-value 쌍**으로 데이터를 관리하는 associative memory이며, key에는 page number, value에는 frame number가 대응된다.

CPU는 page table보다 TLB를 우선적으로 참조하여, 만약 원하는 page가 TLB에 있는 경우 곧바로 frame number를 얻을 수 있고, 그렇지 않은 경우 메인 메모리에 있는 page table로부터 frame number를 얻을 수 있다.

<img width="684" alt="image" src="https://github.com/user-attachments/assets/addaf36d-cb45-429e-aa0a-313ef63f5dfc" />


원하는 엔트리가 TLB에 존재하는지 알기 위해선 TLB 전체를 다 찾아봐야 하는 단점이 있다. 다만, parallel search가 가능하므로 탐색하는 시간은 적다.

TLB의 성능을 높이고 싶다면 page의 크기를 키우는 방법이 있다.

TLB에서 찾아지는 비율을 a라고 하고, TLB를 탐색하는데 걸리는 시간을 b라고 하면, 메모리 접근 횟수의 기댓값은

TLB에서 찾은 경우 + 못 찾은 경우 = (b+1)_a + (b+2)_(1-a) = **2+b-a**가 된다.

b는 일반적으로 매우 작은 값이고, a는 값이 크다. 실제로 Block이 어디에나 위치할 수 있어 Cache miss의 문제가 적기 때문이다.

따라서 기존의 메모리 접근 횟수인 2보다 훨씬 작은 값이 된다.

Context Switch가 발생하는 경우에는 TLB가 어떻게 처리될까?

먼저, 매 Switch마다 TLB 전체를 비우는 방법이 있다. 이 방법은 당연하게도 비용이 비싸다는 단점이 있다.

따라서, **TLB의 각 엔트리가 어느 프로세스를 위한 것인지 추적하여 이용되지 않는 엔트리만 비우는 게 좋다.** 이를 **ASID(Address Space Identifier)**를 이용하여 해결한다.

ASID는 Process ID와 유사하지만 8bit로, 32bit인 PID보다 저렴하다. 동일한 ASID를 갖는 프로세스끼리는 TLB를 공유할 수 있기 때문에, 이런 경우엔 TLB를 비우는 오버헤드를 줄일 수 있다.

TLB miss가 난 경우에는 하드웨어와 운영체제가 모두 관여한다.

하드웨어가 page table에서 유효한 엔트리가 있는지를 확인한다. 만약 유효한 엔트리가 없다면 page fault를 발생시키고 이를 운영체제가 다룬다.

그리고 TLB miss가 발생하면 CPU가 운영체제에 trap을 발생시켜 커널 모드로 바꾼 뒤 명령어를 TLB에 load 한 후 재시작한다.

#### Structure of the Page Table

**1. Multi-level paging**

**논리적 주소 공간을 여러 단계의 page table로 분할하여 오직 사용되는 page의 page table만 할당하는 기법**이다. 이를 통해 각각의 page table이 Noncontiguously 하게 할당되도록 하는 것이 목표이다.

간단한 예로 Two-level paging을 살펴보자.

Two-level paging은 말 그대로 page table과 메모리 사이에 page table을 하나 더 둠으로써 두 단계를 거치는 방법이다. 이를 통해 모든 page를 로드해야 하는 부담을 줄일 수 있다.

![](https://blog.kakaocdn.net/dn/0SoAg/btrgcBD4m2g/XFXU2sq47DprLAJRV9ftB0/img.png)

기존에는 32 bit 논리적 주소 공간이라면, 20 bit는 page number, 12 bit는 page offset을 나타냈는데, Two-level인 경우, page table 자체가 page로 구성되기 때문에 page number는 10 bit의 page number와 10 bit의 page offset으로 또 나뉘게 된다.

![](https://blog.kakaocdn.net/dn/uopBK/btrgfMrxxSJ/pzob2zKZV11ShbwCCIpAek/img.png)

![](https://blog.kakaocdn.net/dn/bKqEuE/btrga3H3QG1/KxRZ2A1TXvO2yeGrO7BbK0/img.png)

만약 주소 공간이 더 커지면 Multi-level page table이 필요하다.

이 경우 각 단계의 page table이 모두 메모리에 존재하기 때문에 더 많은 메모리 접근이 필요할 수 있는데, 이는 TLB로 해결할 수 있다.

**2. Hashed Page Table**

**hash table을 이용하여 page table을 관리하는 기법**이다. 주소 공간이 32 bit보다 커지면 계층적 paging이 비효율적이므로 이 방식을 사용한다. virtual page number를 해싱하여 page table을 참조하는 데 사용한다. 연결 리스트를 따라가면서 page number를 비교하고 일치하면 대응되는 frame number를 얻는다. 구현하기가 어렵지만 속도는 매우 빠르다.

**3. Inverted Page Table**

지금까지의 page table은 각 page마다 하나의 항목을 가졌다. 반대로 Inverted page table은 **메모리의 frame마다 한 항목씩 할당하는데, 그러면 physical frame에 대응하는 항목만 저장하면 되므로 메모리를 훨씬 적게 사용한다.** **각 page table entry는 각각의 메모리의 frame이 담고 있는 내용(PID, logical address)을 표시한다.**

다만 테이블 전체를 탐색해야 하므로 시간이 오래 걸리는 단점이 있어 대부분의 메모리는 Hashed page table과 Inverted page table의 결합으로 이루어져 있다.

![](https://blog.kakaocdn.net/dn/NIJCC/btrf7z1MBtE/EmotYTRTF8psWljLjWkWyK/img.png)

##### 2. 세그먼테이션 기법(segmentation)

> 세그먼테이션 기법은 가상기억장치 내의 프로세스를 가변적인 크기의 블록으로 나누고 메모리를 할당
> 분할 형태가 배열이나 함수와 같은 논리적인 다양한 크기의 가변적인 크기로 관리

**Segmentation은 의미 단위로 하나의 프로세스를 나누는 것을 말한다.** 작게는 프로그램을 구성하는 함수 하나하나를, 크게는 프로그램 전체를 하나의 Segment로 정의할 수 있다. 일반적으로는 code, data, stack 부분이 하나의 세그먼트로 정의된다.

Segmentation의 논리적 주소는 **<segment number, offset>**으로 구성되며, 각각의 segment는 base, limit, protection bit을 가지고 있다.

Segmentation의 장점은, paging과 마찬가지로 segment들이 연속적으로 할당될 필요가 없고, stack과 heap이 독립적으로 커질 수 있으며, segment마다 protection을 따로 수행할 수 있는 등 paging과 유사한 장점을 가지고 있다.

다만, 각각의 segment는 반드시 연속적으로 할당해야 하는 단점이 있다.

##### 3. 페이징/세그먼테이션 혼용기법

외부 단편화 및 내부 단편화 최소화를 위하여 세그먼테이션 기법과 페이징 기법을 결합한 페이징/ 세그먼테이션 기법이 개발되었다.

### 메모리 관리 기법

#### 1. 반입 기법

주기억장치에 적재할 다음 프로세스의 반입 시기를 결정
메모리로 적재 시기 졀정(When)

- 요구 반입 기법
- 예상 반입 기법

#### 2. 배치 기법

디스크에 있는 프로세스를 주기억장치의 어느 위치에 저장할 것인지 결정하는 기법
메모리 적재 위치 결정(Where)

- 최초 적합(First-fit)
- 최적 적합(Best-fit)
- 최악 적합(Worst-fit)

#### 3. 할당 기법

실행해야할 프로세스를 주기억장치에 어떤 방법으로 할당할 것인지 결정하는 기법
메모리 적재 방법 결정(How)

- 연속 할당 기법
- 분산 할당 기법

#### 4. 교체 기법

재배치 기법으로 주기억장치에 있는 프로세스 중 어떤 프로세스를 제거할 것인지를 결정하는 기법
메모리 교체 대상 결정(Who)

- 프로세스의 Swap In/Out
- Fifo, Optimal, LRU, LFU, 시계 알고리즘, MFU

### 메모리 배치 기법

메모리 배치 기법에는 최초 적합, 최적 적합, 최악 적합

| 기법      | 설명                                                                         |
| --------- | ---------------------------------------------------------------------------- |
| 최초 적합 | 프로세스가 적재될 수 있는 가용 공간 중에서 첫번째 분할에 할당하는 방식       |
| 최적 적합 | 가용 공간 중에서 가장 크기가 비슷한 공간을 선택하여 프로세스를 적재하는 방식 |
| 최악 적합 | 프로세스의 가용 공간중에서 가장 큰 공간에 할당하는 방식                      |

### 메모리 할당 기법

프로세스를 실행시키기 위해 주기억장치에 어떻게 할당할 것인지에 대한 내용
연속할당 기법과, 분산 할당 기법으로 분류

#### 1. 연속 할당 기법

실행을 위한 각 프로세스를 주기억장치 공간내에서 인접되게 연속하여 저장하는 방법
프로세스를 주기억장치에 연속으로 할당하는 기법

- 단일 분할 할당 기법(오버레이, 스와핑)
- 다중 분할 할당 기법(고정 분할 할당기법, 동적 분할 할당 기법)

#### 2. 분산 할당 기법

하나의 프로세스를 여러 개의 조각으로 나누어 주기억장치 공간 내 분산하여 배치하는 기법
주로 가상기억장치에서 사용

- 페이징 기법
- 세그먼테이션 기법
- 페이징/세그먼테이션 기법

### 교체 기법

주기억 장치에 있는 프로세스 중 어떤 프로세스를 제거할 것인지 결정하는 기법
새로운 페이지를 할당하기 위해 현재 할당된 페이지 중 어느것과 교체할지 결정

#### FIFO

각 페이지가 주기억장치에 적재될 때마다 그때의 시간을 기억시켜 가장 먼저 들어와 가장 오래있던 페이지 교체(선입선출)

#### LRU(Least Recently Used)

사용된 시간을 확인하여 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체

#### LFR(Least Frquently Used)

사용된 횟루를 확인하여 참조횟수가 가장 적은 페이지를 선택하여 교체

#### OPT(Optimal Replacement)

앞으로 가장 오랫동안 사용하지 않을 페이지 교체

#### NUR(Not Used Recently)

LRU 와 비슷한 알고리즘으로 최근에 사용하지 않은 페이지를 교체
다른 점은 참조 비트와 변형 비트 사용

#### SCR(Second Chance Replacemnet)

가장 오랫동안 주기억장치에 있던 페이지 중 자주 사용되는 페이지의 교체를 방지하기 위한 기법으로 FIFO 단점 보완

### 메모리 단편화

분활된 주기억장치에 프로세스를 할당, 반납 과정에서 사용되지 못하고 낭비되는 기억장치가 발생하는 현상

#### 1. 내부 단편화

분할된 공간에 프로세스를 적재한 후 남은 공간
고정 분할 할당 방식 또는 페이징 기법 사용시 발생

#### 해결법

슬랩 할당자(slab Allocator): 페이지 프레임을 할당받아 공간을 작은 크키로 분할하고(캐시 집합) 메모리 요청시 작은 크기로 메모리를 할당/ 해제 하는 동적 메모리 관리 기법
통합(coalescing): 인접한 단편화 영역을 찾아 하나로 통합
압축(Compaction): 메모리의 모든 단편화 영역을 하나로 압축

#### 2. 외부 단편화

할당된 크키가 프로세스 크기보다 작아서 사용하지 못하는 공간
외부 단편화는 가변 분할 할당 방식 또는 세그멘테이션 기법 사용시 발생

#### 해결법

버디 메모리 할당(Buddy memory allocatiion): 요청한 프로세스 크기에 가장 알맞은 크기를 할당하기 위해 메모리를 `2**n` 의 크기로 분할하여 메모리를 할당
통합(Coalsescing): 인접한 단편화 영역을 찾아 하나로 통합하는 기법
압축(Compaction): 메모리의 모든 단편화 영역을 하나로 압축하는 기법

### 페이징 기법의 문제 및 해결방안

#### 1. 스레싱

어떤 프로세스가 계속적으로 페이지 부재가 발생하여 프로세스의 실제 처리 시간 보다 페이지 교체 시간이 더 많아지는 현상
오류율이 클수록 스레싱이 많이 발생한 것이고, 스레싱으로 인해 전체 시스템의 성능 및 처리율은 저하
페이지 부재가 계속 증가하여 기억장치 접근 시간 증가

#### 2. 페이징 기법의 문제점 해결방안

1. 워킹세트(Working Set)
   - 각 프로세스들이 많이 참조하는 페이지들의 집합을 주기억장치 공간에 계속 상주하게 하여 빈번한 페이지 교체 현상을 줄이고자 하는 기법
   - 장점: 멀티프로그래밍 정도를 높일 수 있고(Page hit 증가), cpu 활용률 최적화
   - 단점: 워킹 세트 추적관리가 복잡하고, 워킹 세트 크기 설정의 모호함이 발생
2. 페이지 부재 빈도(PFF: Page-Fault Frequency)
   - 페이지 부재 빈도는 페이지 부재율의 상한과 하한을 정해서 직접적으로 페이지 부재율을 예측하고 조절하는 기법
   - 페이지 부재 비율에 따라 페이지 프레임 개수를 조절한다.
   - 장점: 페이지 부재 발생시 실행하여 부ㅈ하가 적고, 직접적으로 페이지 부재율 조절이 가능한 기법
   - 단점: 프로세르르 중지시키는 과정이 발생하고, 페이지 참조가 새로운 지역성으로 이동할 수 있음

### 지역성(Locality)

지역성은 프로세스가 실행되는 동안 주기억장치를 참조할 때 일부 페이지만 집중적으로 참조하는 특성
프로세스가 집중적으로 사용하는 페이지를 알아내는 방법의 하나로, 가상기억 장치 관리의 이론적인 근거가 됨
지역성은 스레싱을 방지하기 위해 워킹 셋 이론의 기반 됨
참조 지역성(Locality of Reference) 이라고도 불림

#### 지역성의 유형

| 유형        | 설명                                                                                                                          | 사례                                                                                                         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------- |
| 시간 지역성 | 최근 사용되었던 기억장소들이 집중적으로 액세스하는 현상<br>참조했던 메모리는 빠른 시간에 다시 참조될 확률이 높은 특성         | Loop, 스택, sub routine, Counting, 집계에 사용되는 변수                                                      |
| 공간 지역성 | 프로세스 실행시 일정 위치의 페이지를 집중적으로 액세스하는 현상<br>참조된 메모리 근처의 메모리를 참조하는 특성                | 배열 순회, 프로그래머들이 관련된 변수들을 서로 근처에 선언하여 할당되는 기억장소, 같은 영역에 있는 변수 참조 |
| 순차 지역성 | 데이터가 순차적으로 액세스 되는 현상<br>프로그램 내의 명령어가 순차적으로 구성된 특성<br>공간 지역성에 편입되어 설명되기도 함 | 순차적 코드 실행                                                                                             |

## 프로세스

프로세스는 cpu에 의해 처리되는 프로그램
실행중인 프로그램을 의미, 작업(Job) 또는 태스크(task)라고도 함

### 프로세스 상태

- 생성 상태: 사용자에 의해 프로세스가 생성된 상태
- 준비 상태: cpu를 할당받을 수 있는 상태, 준비 리스트에 대기
- 실행 상태: 프로세스가 cpu를 할당받아 동작 중인 상태
- 대기 상태: 프로세스 실행 중 입출력 처리 등으로 인해 cpu를 양도하고 입출력 처리가 완료까지 대기 리스트에서 기다리는 상태
- 완료 상태: 프로세스가 cpu를 할당받아 주어진 시간 내에 완전히 수행을 종료한 상태

### 프로세스 상태 전이
<img width="672" alt="image" src="https://github.com/user-attachments/assets/e8a392a0-ffc1-4445-9a4b-ae0c557f72db" />


#### 디스패치(dispatch)

준비 상태에 있는 여러 프로세스 중 실행될 프로세스를 선정(scheduling) 하여 cpu를 할당 -> 문맥교환 발생, 프로세스는 준비상태에서 실행 상태로 전이

#### 타이머 런 아웃 = 할당 시간 초과

cpu를 할당받은 프로세스는 지정된 시간이 초과되면 스케줄러에 의해 pcb를 저장, cpu 반납 후 다시 준비상태로 전이됨, 프로세스는 실행 상태에서 준비상태로 전이, 타임 슬라이스 만료, 선점시 타임아웃 발생

#### 블록 = 입출력 발생

실행 상태에 있는 프로세스가 지정된 할당시간을 초과하기 전에 입출력이나 기타 사건이 발생(block)하면 cpu를 스스로 반납하고 입출력이 완료될 때가지 대기 상태로 전이됨, 프로세스는 실행 상태에서 대기 상태로 전이, 즉시 실행 불가능한 시스템 콜 I/O 작업시작, 프로세스간 통신 시 Block 발생

#### 웨이크 업(wake-up)

어느 순간에 입출력이 종료되면 대기 상태의 프로세스에게 입출력 종료 사실을 알려주고, 준비 상태로 전이됨
프로세스는 대기 상태에서 준비 상태로 전이

### 프로세스 스케줄링

cpu를 사용하려고 하는 프로세스 사이의 우선순위 관리하는 작업, 스케줄링은 처리율과 cpu 이용률을 증가시키고, 오버헤드, 응답시간, 반환시간, 대기시간을 최소화시키기 위한 기법
특정 프로세스가 적합하게 실행되도록 프로세스 스케줄링에 의해 프로세스사이에서 cpu 교체가 일어난다.

#### 서비스 시간(Brust Time)

프로세스가 결과를 산출하기까지 소요되는 시간

#### 응답 시간(Response Time)

프로세스들이 입력되어 서비스를 요청하고, 반응하기 시작할 때가지 소요되는 시간

#### 반환시간

프로세스들이 입력되어 서비스를 수행하고 결과를 산출하기까지 소용되는 시간

> 반환시간 = 대기시간 + 수행시간

#### 대기 시간

프로세스가 프로세서에 할당되기까지 큐에 대기하는 시간
프로세스가 도착 즉시 프로세서에 할당되면 대기시간은 0이 됨

#### 평균 대기시간

프로세스가 준비 큐에더 대기하는 평균 시간
대기시간이 0인 프로세스도 평균 대기시간에 합산하여 결과 도출

#### 종료시간

프로세스가 요구하는 서비스 시간을 모두 수행하고 종료하는 시간

#### 시간할당량

한 프로세스가 프로세서를 독점하는 것을 방지하기 위해 서비스되는 시간 할당량

#### 응답률

HRN 스케줄링에서 사용
HRN에서 응답률이 높으면 우선순위가 높다고 판단

> (대기시간 + 서비스 시간) / 서비스 시간

### 프로세스 스케줄링 유형

선점형과 비선점형이 있다.

#### 1. 선점형 스케줄링

하나의 프로세스가 cpu를 차지하고 있을때, 우선순위가 높은 다른 프로세스가 현재 프로세스를 중단시키고 cpu를 점유하는 스케줄링 방식

장점: 비교적 빠른 응답, 대화식 시분할 시스템에 적합
단점: 높은 우선순위 프로세스들이 들어오는 경우 오버헤드 초래

알고리즘

- SRT
- 단단계 큐
- 다단계 피드백 큐
- 라운드 로빈

활용: 실시간 응답 환경, Deadline 응답 환경

#### 2. 비선점형 스케줄링(Non Preemptive Scheduling)

한 프로세스가 cpu를 할당받으면 작업 종료 후 cpu 반환 시 까지 다른 프로세스는 cpu 점유가 불가능한 스케줄링 방식

장점: 응답시간 예상이 용이, 모든 프로세스에 대한 요구를 공정하게 처리
단점: 짧은 작업을 수행하는 프롯스가 긴 작업 종료 시까지 대기

알고리즘

- 우선순위
- 기한부
- HRN
- FCFS
- SJF
  활용: 처리 시간 편차가 적은 특정 프로세스 환경

### 프로세스 스케줄링 알고리즘

#### 1. 선점형 스케줄링 알고리즘

SRT: 가장 짧은 시간이 소요되는 프로세르르 먼저 수행, 남은 처리시간이 더 짧다고 판단되는 프로세스가 준비 큐에 생기면 언제라도 프로세스가 선점되는 스케줄링 기법, 비선점 방식의 스케줄링 기법에 선점 방식을 도입한 기법

MLQ(Multi Level Queue): 작업을 여러 종류 그룹으로 분할하고, 여러 개의 큐를 이용하여 상위단계 작업에 의한 하위단계 작업이 선점 당하는 스케줄링 기법, 각 큐는 자신만의 독자적인 스케줄링을 가짐

MLFQ(Muti Level Feedback Queue): 새로운 프로세스는 높은 우선순위가 부여되고, 프로세스의 실행시간이 길어질수록 점점 낮은 우선순위 큐로 이동하고 마지막 단계는 라운드 로빈 방식이 적용되는 스케줄링 기법, 입출력 위주와 CPU 위주인 프로세스의 특성에 따라 큐마다 서로 다른 CPU 시간 할당량 부여, FCFS와 라운드 로빈 스케줄링 기법을 혼합한 방식

RR(라운드 로빈): 모든 프로세스에 대해 같은 크기의 CPU 시간을 할당하고, 프로세스가 할당된 시간 내에 처리 완료를 못하면 준비 큐 리스트의 가장 뒤로 보내지고, CPU는 대기중인 다음 프로세스로 넘어가는 스케줄링 기법

#### 2. 비선점형 스케줄링 알고리즘

우선순위(Priority): 프로세스 별로 우선순위가 주어지고, 우선순위에 따라 cpu를 할당하는 스케줄링 기법, 동일 순위는 FCFS 방식 적용, 주요/ 긴급 프로세스에 대한 우선 처리 및 설정, 자원 상황등에 따른 우선순위 선정이 가능한 기법

기한부(Deadline): 작업들이 명시된 시간이나 기한 내에 완료되도록 계획하는 스케줄링 기법, 요청에 명시된 시간 내 처리르 보장하는 기법

HRN(HIghest Response Ratio Next): 대기중인 프로세스 중 현재 응답률이 가장 높은 것을 선택하는 스케줄링 기법, SJF의 약점인 기아 현상을 보완한 기법으로 긴 작업과 짧은 작업 간의 불평등 완화

FCFS: 프로세스가 준비 큐에 도착한 순서에 따라 CPU를 할당하는 스케줄링 기법, FIFO 알고리즘

SJF: 모든 프로세스에 대해 같은 크기의 CPU 시간을 할당하고, 프로세스가 할당된 시간 내에 처리 완료를 못하면 준비 큐 리스트의 가장 뒤로 보내지고, CPU는 대기 중인 다음 프로세스로 넘어가는 스케줄링

반환시간 = 종료시간 - 도착 시간
대기시간 - 반환시간 - 서비스 시간

### 교착상태

<img width="521" alt="image" src="https://github.com/user-attachments/assets/cbc95acd-e00a-4ded-b282-7bf65ed42679" />


다중 프로세싱 환경에서 두 개 이상의 프로세스가 특정 자원할당을 무한정 대기

#### 교착상태 발생 조건

##### 1. 상호배제(Mutual Exclusive)

프로세스가 자원을 배타적으로 점유하여 다른 프로세스가 그 자원을 사용할 수 없는 상태

##### 2. 점유와 대기(Hold & wait)

한 프로세스가 자원을 점유하고 있으면서 또 다른 자원을 요청하여 대기하고 있는 상태

##### 3. 비선점(non preemption)

한 프로세스가 점유한 자원에 대해 다른 프로세스가 선점할 수 없고, 오직 점유한 프로세스만이 해제 가능한 상태

##### 환형 대기(Circular wait)

두 개 이상의 프로세스 간 자원의 점유와 대기가 하늬 원형을 구성한 상태

#### 교착상태 해결법

##### 1. 예방(Prevention)

상호 배제를 제외한 나머지 교착상태 발생 조건을 위배하는 방안
점유 자원 해제 후 새 자원 요청

##### 2. 회피(Avoidance)

안전한 상태를 유지할 수 있는 요구만 수락(프로세스별 자원 최대요구량 확보)
은행가 알고리즘, wound-wait, wait-die

##### 3. 발견(Detection)

시스템의 상태를 감시 알고리즘 통해 교착상태 검사
자원할당 그래프, wait for graph

##### 4. 복구(Recovery)

교착 상태가 없어질 때까지 프로세스를 순차적으로 kill 하여 제거, 희생자 선택해야하고 기아 상태 발생
프로세스 kill, 자원 선점

### 디스크 스케줄링

데이터가 디스크상의 여러 곳에 저장되어 있을 경우, 데이터를 액세스하기 위해 디스크 헤드를 움직이는 경로를 결정하는 기법
OS가 담당하고 처리량 최대화, 응답시간 최소화

FCFS

SSTF

SCAN

C-SCAN

LOOK

N-STEP SCAN

SLTF
